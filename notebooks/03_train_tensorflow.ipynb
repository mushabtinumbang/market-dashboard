{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/_6n50kgs0rq4p_3157kz4sfm0000gn/T/ipykernel_15851/3175276566.py:14: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import HyperModel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os \n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from kerastuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "sys.path.append('../')\n",
    "from src.utilities.config_ import train_data_path, scrape_data_path, model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging level to suppress TensorFlow debug messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              title\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "train_filename = \"finance-dataset.csv\"\n",
    "df = pd.read_csv(os.path.join(train_data_path, train_filename))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into features (X) and labels (y)\n",
    "X = df['title']\n",
    "y = df['label']\n",
    "\n",
    "# convert labels to numeric format\n",
    "label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "y = y.map(label_mapping)\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and pad the sequences\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "max_length = max(len(seq) for seq in X_train_seq)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/sentiment_analysis/tuner0.json\n",
      "{'embedding_output_dim': 256, 'lstm_units': 96, 'dropout_rate': 0.5, 'dense_units': 128, 'learning_rate': 0.00222084508546812}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "97/97 [==============================] - 11s 97ms/step - loss: 0.8463 - accuracy: 0.6361 - val_loss: 0.7441 - val_accuracy: 0.6765 - lr: 0.0022\n",
      "Epoch 2/30\n",
      "97/97 [==============================] - 9s 94ms/step - loss: 0.5414 - accuracy: 0.7884 - val_loss: 0.7600 - val_accuracy: 0.6624 - lr: 0.0022\n",
      "Epoch 3/30\n",
      "97/97 [==============================] - 9s 93ms/step - loss: 0.2955 - accuracy: 0.9019 - val_loss: 0.8047 - val_accuracy: 0.7165 - lr: 0.0022\n",
      "Epoch 4/30\n",
      "97/97 [==============================] - 9s 95ms/step - loss: 0.1167 - accuracy: 0.9700 - val_loss: 1.0656 - val_accuracy: 0.7281 - lr: 4.4417e-04\n"
     ]
    }
   ],
   "source": [
    "# HyperModel class for Keras Tuner\n",
    "class SentimentHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=5000, output_dim=hp.Int('embedding_output_dim', 64, 256, step=64), input_length=max_length))\n",
    "        model.add(Bidirectional(LSTM(hp.Int('lstm_units', 32, 128, step=32), return_sequences=True)))\n",
    "        model.add(Dropout(hp.Float('dropout_rate', 0.3, 0.5, step=0.1)))\n",
    "        model.add(Bidirectional(LSTM(hp.Int('lstm_units', 32, 128, step=32))))\n",
    "        model.add(Dropout(hp.Float('dropout_rate', 0.3, 0.5, step=0.1)))\n",
    "        model.add(Dense(hp.Int('dense_units', 32, 128, step=32), activation='relu'))\n",
    "        model.add(Dropout(hp.Float('dropout_rate', 0.3, 0.5, step=0.1)))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Float('learning_rate', 1e-4, 1e-2, sampling='LOG')),\n",
    "                      loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = RandomSearch(\n",
    "    SentimentHyperModel(),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='sentiment_analysis'\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(X_train_pad, y_train, epochs=10, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=3), ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-5)])\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.values)\n",
    "\n",
    "# Build the model with the best hyperparameters and train it\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "history = best_model.fit(X_train_pad, y_train, epochs=30, batch_size=32, validation_split=0.2, callbacks=[EarlyStopping(monitor='val_loss', patience=3), ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 70, 256)           1280000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 70, 192)          271104    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 70, 192)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 192)              221952    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 192)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               24704     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,798,147\n",
      "Trainable params: 1,798,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 25ms/step - loss: 0.9802 - accuracy: 0.7557\n",
      "31/31 [==============================] - 1s 22ms/step\n",
      "Test Accuracy: 0.7556701302528381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.58      0.63       110\n",
      "     neutral       0.79      0.87      0.82       571\n",
      "    positive       0.71      0.61      0.65       289\n",
      "\n",
      "    accuracy                           0.76       970\n",
      "   macro avg       0.72      0.68      0.70       970\n",
      "weighted avg       0.75      0.76      0.75       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = best_model.evaluate(X_test_pad, y_test)\n",
    "\n",
    "# Generate a classification report\n",
    "y_pred = best_model.predict(X_test_pad)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred_classes, target_names=label_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to tensorflow_model\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "tensorflow_file = \"tensorflow_model\"\n",
    "best_model.save(os.path.join(model_path, tensorflow_file))\n",
    "print(f\"Model saved to {tensorflow_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 22ms/step - loss: 0.9802 - accuracy: 0.7557\n",
      "Test Accuracy: 0.7556701302528381\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(os.path.join(model_path, tensorflow_file))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = loaded_model.evaluate(X_test_pad, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market-dashboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
