{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to avoid warnings\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys \n",
    "\n",
    "\"\"\"\n",
    "Sklearn Libraries\n",
    "\"\"\"\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"\n",
    "Transformer Libraries\n",
    "\"\"\"\n",
    "from transformers import BertTokenizer,  AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "\"\"\"\n",
    "Pytorch Libraries\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "\n",
    "sys.path.append('../')\n",
    "from src.utilities.config_ import train_data_path, combined_data_path\n",
    "import src.utilities.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>2</td>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>1</td>\n",
       "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>2</td>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>2</td>\n",
       "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4846</th>\n",
       "      <td>2</td>\n",
       "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "1         1  According to Gran , the company has no plans t...\n",
       "2         1  Technopolis plans to develop in stages an area...\n",
       "3         2  The international electronic industry company ...\n",
       "4         0  With the new production plant the company woul...\n",
       "5         0  According to the company 's updated strategy f...\n",
       "...     ...                                                ...\n",
       "4842      2  LONDON MarketWatch -- Share prices ended lower...\n",
       "4843      1  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
       "4844      2  Operating profit fell to EUR 35.4 mn from EUR ...\n",
       "4845      2  Net sales of the Paper segment decreased to EU...\n",
       "4846      2  Sales in Finland decreased by 10.5 % in Januar...\n",
       "\n",
       "[4846 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "data = pd.read_csv(os.path.join(train_data_path, \"finance-dataset.csv\"),\n",
    "                   encoding='latin-1', \n",
    "                    names=['label', 'text']).iloc[1:]\n",
    "\n",
    "# Convert labels to integers\n",
    "label_to_int = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "data['label'] = data['label'].map(label_to_int)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "# Load the FinBERT model\n",
    "model = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4846/4846 [00:01<00:00, 2597.49 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrame to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(data)\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=64)  # You can adjust the max_length as needed\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Rename the label column to \"labels\" for the trainer\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Remove unnecessary columns\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
    "\n",
    "# Convert to torch tensors\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_test_split = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments with evaluation steps\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=4,  # Set a high number of epochs to allow for early stopping\n",
    "    per_device_train_batch_size=8,  # Adjust based on your memory\n",
    "    per_device_eval_batch_size=16,  # Adjust based on your memory\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,  # Log every 100 steps\n",
    "    evaluation_strategy=\"steps\",  # Evaluate every 'eval_steps'\n",
    "    eval_steps=500,  # Evaluation interval, adjust based on your dataset size\n",
    "    log_level=\"error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4521, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 0.7295, 'learning_rate': 2e-05, 'epoch': 0.41}\n",
      "{'loss': 0.5691, 'learning_rate': 3e-05, 'epoch': 0.62}\n",
      "{'loss': 0.6397, 'learning_rate': 4e-05, 'epoch': 0.82}\n",
      "{'loss': 0.5958, 'learning_rate': 5e-05, 'epoch': 1.03}\n",
      "{'eval_loss': 0.5578722357749939, 'eval_accuracy': 0.8072164948453608, 'eval_runtime': 50.225, 'eval_samples_per_second': 19.313, 'eval_steps_per_second': 1.215, 'epoch': 1.03}\n",
      "{'loss': 0.4561, 'learning_rate': 4.652777777777778e-05, 'epoch': 1.24}\n",
      "{'loss': 0.4593, 'learning_rate': 4.305555555555556e-05, 'epoch': 1.44}\n",
      "{'loss': 0.4638, 'learning_rate': 3.958333333333333e-05, 'epoch': 1.65}\n",
      "{'loss': 0.417, 'learning_rate': 3.611111111111111e-05, 'epoch': 1.86}\n",
      "{'loss': 0.3437, 'learning_rate': 3.263888888888889e-05, 'epoch': 2.06}\n",
      "{'eval_loss': 0.7420837879180908, 'eval_accuracy': 0.8309278350515464, 'eval_runtime': 40.4004, 'eval_samples_per_second': 24.01, 'eval_steps_per_second': 1.51, 'epoch': 2.06}\n",
      "{'loss': 0.1994, 'learning_rate': 2.916666666666667e-05, 'epoch': 2.27}\n",
      "{'loss': 0.2438, 'learning_rate': 2.5694444444444445e-05, 'epoch': 2.47}\n",
      "{'loss': 0.1776, 'learning_rate': 2.2222222222222223e-05, 'epoch': 2.68}\n",
      "{'loss': 0.2188, 'learning_rate': 1.8750000000000002e-05, 'epoch': 2.89}\n",
      "{'loss': 0.1197, 'learning_rate': 1.527777777777778e-05, 'epoch': 3.09}\n",
      "{'eval_loss': 0.8685851693153381, 'eval_accuracy': 0.8525773195876288, 'eval_runtime': 39.8108, 'eval_samples_per_second': 24.365, 'eval_steps_per_second': 1.532, 'epoch': 3.09}\n",
      "Stopping training as eval_accuracy has reached 0.8525773195876288\n",
      "{'train_runtime': 2168.8505, 'train_samples_per_second': 7.148, 'train_steps_per_second': 0.894, 'train_loss': 0.6723511295318604, 'epoch': 3.09}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=0.6723511295318604, metrics={'train_runtime': 2168.8505, 'train_samples_per_second': 7.148, 'train_steps_per_second': 0.894, 'train_loss': 0.6723511295318604, 'epoch': 3.09})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "import numpy as np\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, threshold: float, metric: str = \"eval_accuracy\"):\n",
    "        self.threshold = threshold\n",
    "        self.metric = metric\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        if state.log_history and self.metric in state.log_history[-1]:\n",
    "            accuracy = state.log_history[-1][self.metric]\n",
    "            if accuracy > self.threshold:\n",
    "                control.should_training_stop = True\n",
    "                print(f\"Stopping training as {self.metric} has reached {accuracy}\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "# Define the custom callback with your threshold\n",
    "early_stopping_callback = EarlyStoppingCallback(threshold=0.85, metric=\"eval_accuracy\")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    compute_metrics=compute_metrics,  # Define a compute_metrics function to calculate accuracy\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8525773195876288, 'f1': 0.852897273228443, 'precision': 0.8533935043857552, 'recall': 0.8525773195876288}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Define the metric function\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = compute_metrics(predictions)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 970\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive']\n"
     ]
    }
   ],
   "source": [
    "# Your new text\n",
    "new_text = [\"This is a sample financial news article. The market is looking bad.\", \"Market is looking great now\"]\n",
    "\n",
    "# Tokenize the new text\n",
    "inputs = tokenizer(new_text, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "\n",
    "# Move inputs to the appropriate device (e.g., CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# Map predictions to labels\n",
    "int_to_label = {0: 'positive', 1: 'neutral', 2: 'negative'}\n",
    "predicted_labels = [int_to_label[pred.item()] for pred in predictions]\n",
    "\n",
    "print(predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../model/finbert/tokenizer_config.json',\n",
       " '../model/finbert/special_tokens_map.json',\n",
       " '../model/finbert/vocab.txt',\n",
       " '../model/finbert/added_tokens.json')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to save the model and tokenizer\n",
    "save_directory = \"../model/finbert/\"\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the saved directory\n",
    "save_directory = \"../model/finbert/\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(save_directory)\n",
    "\n",
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dummy training arguments (only `per_device_eval_batch_size` is relevant here)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_eval_batch_size=16,  # Adjust based on your memory\n",
    ")\n",
    "\n",
    "# Create Trainer instance with the loaded model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args\n",
    ")\n",
    "\n",
    "# Predict on the test dataset\n",
    "predictions = trainer.predict(test_dataset)\n",
    "preds = np.argmax(predictions.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8525773195876288\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.80      0.80       271\n",
      "     neutral       0.89      0.88      0.88       583\n",
      "    positive       0.81      0.84      0.83       116\n",
      "\n",
      "    accuracy                           0.85       970\n",
      "   macro avg       0.83      0.84      0.84       970\n",
      "weighted avg       0.85      0.85      0.85       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Extract the true labels\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(true_labels, preds, target_names=['negative', 'neutral', 'positive'])\n",
    "accuracy = accuracy_score(true_labels, preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_finbert(\n",
    "        df,\n",
    "        loaded_model,\n",
    "        loaded_tokenizer\n",
    "):\n",
    "    # New text data to predict\n",
    "    titles = list(df['title'])\n",
    "\n",
    "    # Tokenize the new text\n",
    "    inputs = loaded_tokenizer(titles, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\")\n",
    "\n",
    "    # Move inputs to the appropriate device (e.g., CPU or GPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    loaded_model.to(device)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "    \n",
    "    # Make predictions\n",
    "    loaded_model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "    # Map predictions to labels\n",
    "    int_to_label = {0: 'positive', 1: 'neutral', 2: 'negative'}\n",
    "    predicted_labels = [int_to_label[pred.item()] for pred in predictions]\n",
    "\n",
    "    df[\"label\"] = predicted_labels\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "1  Technopolis plans to develop in stages an area...\n",
       "2  The international electronic industry company ...\n",
       "3  With the new production plant the company woul...\n",
       "4  According to the company 's updated strategy f...\n",
       "5  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...\n",
       "6  For the last quarter of 2010 , Componenta 's n...\n",
       "7  In the third quarter of 2010 , net sales incre...\n",
       "8  Operating profit rose to EUR 13.1 mn from EUR ...\n",
       "9  Operating profit totalled EUR 21.1 mn , up fro..."
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the saved directory\n",
    "save_directory = \"../model/finbert/\"\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(save_directory)\n",
    "\n",
    "# Load the model\n",
    "model = BertForSequenceClassification.from_pretrained(save_directory)\n",
    "\n",
    "df = df.drop(columns=\"label\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     label\n",
       "1  Technopolis plans to develop in stages an area...   neutral\n",
       "2  The international electronic industry company ...  negative\n",
       "3  With the new production plant the company woul...  positive\n",
       "4  According to the company 's updated strategy f...  positive\n",
       "5  FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is ag...  positive\n",
       "6  For the last quarter of 2010 , Componenta 's n...  positive\n",
       "7  In the third quarter of 2010 , net sales incre...  positive\n",
       "8  Operating profit rose to EUR 13.1 mn from EUR ...  positive\n",
       "9  Operating profit totalled EUR 21.1 mn , up fro...  positive"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = predict_with_finbert(df, model, tokenizer)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gold, Silver Q3 Technical Forecast: Gold's Ran...</td>\n",
       "      <td>30-06-2024</td>\n",
       "      <td>https://www.dailyfx.com/analysis/gold-silver-q...</td>\n",
       "      <td>forex</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dailyfx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitcoin Q3 Fundamental Outlook – Short-Term Mu...</td>\n",
       "      <td>30-06-2024</td>\n",
       "      <td>https://www.dailyfx.com/news/bitcoin-q3-fundam...</td>\n",
       "      <td>forex</td>\n",
       "      <td>positive</td>\n",
       "      <td>dailyfx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crude Oil Q3 Technical Forecast: Narrowing Pri...</td>\n",
       "      <td>29-06-2024</td>\n",
       "      <td>https://www.dailyfx.com/analysis/crude-oil-q3-...</td>\n",
       "      <td>forex</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dailyfx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Equities Q3 Fundamental Outlook: Bullish Momen...</td>\n",
       "      <td>29-06-2024</td>\n",
       "      <td>https://www.dailyfx.com/news/equities-q3-funda...</td>\n",
       "      <td>forex</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dailyfx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>British Pound Q3 Technical Forecast: GBP/USD E...</td>\n",
       "      <td>29-06-2024</td>\n",
       "      <td>https://www.dailyfx.com/analysis/british-pound...</td>\n",
       "      <td>forex</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dailyfx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>Increase in exports, improvement in CAD, mnfg ...</td>\n",
       "      <td>30-06-2024</td>\n",
       "      <td>https://economictimes.indiatimes.com//news/eco...</td>\n",
       "      <td>economy</td>\n",
       "      <td>positive</td>\n",
       "      <td>econtimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>India initiates anti-dumping probe into import...</td>\n",
       "      <td>30-06-2024</td>\n",
       "      <td>https://economictimes.indiatimes.com//news/eco...</td>\n",
       "      <td>economy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>econtimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>2015 skilling policy to be replaced with new one</td>\n",
       "      <td>30-06-2024</td>\n",
       "      <td>https://economictimes.indiatimes.com//news/eco...</td>\n",
       "      <td>economy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>econtimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>India is witnessing high foreign remittances &amp;...</td>\n",
       "      <td>30-06-2024</td>\n",
       "      <td>https://economictimes.indiatimes.com//news/eco...</td>\n",
       "      <td>economy</td>\n",
       "      <td>positive</td>\n",
       "      <td>econtimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>IBBI introduces electronic forms for monitorin...</td>\n",
       "      <td>30-06-2024</td>\n",
       "      <td>https://economictimes.indiatimes.com//news/eco...</td>\n",
       "      <td>economy</td>\n",
       "      <td>neutral</td>\n",
       "      <td>econtimes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1049 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title        date  \\\n",
       "0     Gold, Silver Q3 Technical Forecast: Gold's Ran...  30-06-2024   \n",
       "1     Bitcoin Q3 Fundamental Outlook – Short-Term Mu...  30-06-2024   \n",
       "2     Crude Oil Q3 Technical Forecast: Narrowing Pri...  29-06-2024   \n",
       "3     Equities Q3 Fundamental Outlook: Bullish Momen...  29-06-2024   \n",
       "4     British Pound Q3 Technical Forecast: GBP/USD E...  29-06-2024   \n",
       "...                                                 ...         ...   \n",
       "1044  Increase in exports, improvement in CAD, mnfg ...  30-06-2024   \n",
       "1045  India initiates anti-dumping probe into import...  30-06-2024   \n",
       "1046   2015 skilling policy to be replaced with new one  30-06-2024   \n",
       "1047  India is witnessing high foreign remittances &...  30-06-2024   \n",
       "1048  IBBI introduces electronic forms for monitorin...  30-06-2024   \n",
       "\n",
       "                                                    url category     label  \\\n",
       "0     https://www.dailyfx.com/analysis/gold-silver-q...    forex   neutral   \n",
       "1     https://www.dailyfx.com/news/bitcoin-q3-fundam...    forex  positive   \n",
       "2     https://www.dailyfx.com/analysis/crude-oil-q3-...    forex   neutral   \n",
       "3     https://www.dailyfx.com/news/equities-q3-funda...    forex   neutral   \n",
       "4     https://www.dailyfx.com/analysis/british-pound...    forex   neutral   \n",
       "...                                                 ...      ...       ...   \n",
       "1044  https://economictimes.indiatimes.com//news/eco...  economy  positive   \n",
       "1045  https://economictimes.indiatimes.com//news/eco...  economy   neutral   \n",
       "1046  https://economictimes.indiatimes.com//news/eco...  economy   neutral   \n",
       "1047  https://economictimes.indiatimes.com//news/eco...  economy  positive   \n",
       "1048  https://economictimes.indiatimes.com//news/eco...  economy   neutral   \n",
       "\n",
       "         source  \n",
       "0       dailyfx  \n",
       "1       dailyfx  \n",
       "2       dailyfx  \n",
       "3       dailyfx  \n",
       "4       dailyfx  \n",
       "...         ...  \n",
       "1044  econtimes  \n",
       "1045  econtimes  \n",
       "1046  econtimes  \n",
       "1047  econtimes  \n",
       "1048  econtimes  \n",
       "\n",
       "[1049 rows x 6 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = utils.load(os.path.join(combined_data_path, \"combined_data.feather\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market-dashboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
